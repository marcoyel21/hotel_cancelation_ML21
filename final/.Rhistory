knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(stargazer)
library(stringr)
library(lubridate)
library(Matrix)
library(gamlr)
library(Matrix.utils)
#CARGO LOS DATOS
#____________________
train<-read.csv("data/entrena.csv")
test<-read.csv("data/prueba.csv")
#obtengo el id de observacion para test
test_id<-test %>% select(1)
test<-test %>% select(-1)
# Creo mi Y (1 si se cancelo, 0 eoc)
train$is_canceled<-as.factor(train$is_canceled)
train<- train %>% mutate(y=ifelse(is_canceled=="cancelado",1,0))
train$is_canceled<-NULL
train<-train[,c(which(colnames(train)=="y"),which(colnames(train)!="y"))]
#summary(train)
# aplico el one hot encoding
newdata_train<-train
#newdata_train <-dummy_cols(train,split = T)
newdata_test<-test
#newdata_test <- dummy_cols(test,split = T)
# proporción que queremos de training
training_size <- 0.8
# filas de training
training_rows <- sample(seq_len(nrow(sample_train)),
size=floor(training_size*nrow(sample_train)))
#summary(train)
# aplico el one hot encoding
newdata_train<-train
#newdata_train <-dummy_cols(train,split = T)
newdata_test<-test
#newdata_test <- dummy_cols(test,split = T)
# proporción que queremos de training
training_size <- 0.8
# filas de training
training_rows <- sample(seq_len(nrow(newdata_train)),
size=floor(training_size*nrow(newdata_train)))
#training set
data_training <- sample_train[training_rows,]
# proporción que queremos de training
training_size <- 0.8
# filas de training
training_rows <- sample(seq_len(nrow(newdata_train)),
size=floor(training_size*nrow(newdata_train)))
#training set
data_training <- newdata_train[training_rows,]
#training cuenta con la y
#validation set
# la variable objetivo por separado
data_validation <- newdata_train[-training_rows,-1] #sin la y
y <- sample_train[-training_rows,1]
# proporción que queremos de training
training_size <- 0.8
# filas de training
training_rows <- sample(seq_len(nrow(newdata_train)),
size=floor(training_size*nrow(newdata_train)))
#training set
data_training <- newdata_train[training_rows,]
#training cuenta con la y
#validation set
# la variable objetivo por separado
data_validation <- newdata_train[-training_rows,-1] #sin la y
y <- newdata_train[-training_rows,1]
#Matriz de covariates
#data_training<-sample_train
Xa <-data_training %>% select(-1) #training menos y
Xb <-data_validation
Xc <-equallevels(sample_test,Xa)
#Matriz de covariates
#data_training<-sample_train
Xa <-data_training %>% select(-1) #training menos y
Xb <-data_validation
Xc <-equallevels(newdata_test,Xa)
#summary(train)
# aplico el one hot encoding
newdata_train<-train
#newdata_train <-dummy_cols(train,split = T)
newdata_test<-test
#newdata_test <- dummy_cols(test,split = T)
# proporción que queremos de training
training_size <- 0.8
# filas de training
training_rows <- sample(seq_len(nrow(newdata_train)),
size=floor(training_size*nrow(newdata_train)))
#training set
data_training <- newdata_train[training_rows,]
#training cuenta con la y
#validation set
# la variable objetivo por separado
data_validation <- newdata_train[-training_rows,-1] #sin la y
y <- newdata_train[-training_rows,1]
#Matriz de covariates
#data_training<-sample_train
Xa <-data_training %>% select(-1) #training menos y
Xb <-data_validation
Xc <-equallevels(newdata_test,Xa)
# creo una funcion para que las bases de datos cuenten con los mismos "levels"
# este paso es crucial para asegurarnos que traning, set y el modelo hablen "el mismo idioma", es decir que tengan las mismas variables
equallevels <- function(x, y) {
if (is.data.frame(x) & is.data.frame(y)) {
com <- intersect(x = names(x), y = names(y))
for (i in com) {
if (!is.null(levels(y[[i]]))) {
x[[i]] <- factor(x[[i]], levels = levels(y[[i]]))
}
}
return(x)
} else {
stop("`x` and `y` must be a data.frame.")
}
}
#Matriz de covariates
#data_training<-sample_train
Xa <-data_training %>% select(-1) #training menos y
Xb <-data_validation
Xc <-equallevels(newdata_test,Xa)
#para manejo de nas, si lo quito, por alguna razon la conversion a matriz rala me quita unas obs
options(na.action='na.pass')
#se quita intercepto
#se ponen todas las columnas
Xa <- sparse.model.matrix(~.+0, data = Xa)
Xb <- sparse.model.matrix(~.+0, data = Xb)
Xc <- sparse.model.matrix(~.+0, data = Xc)
#vector de Y´s
Ya<-data_training$y
#CV LASSO
# se hacen 5 folds
cvlasso_a<-cv.gamlr(x = Xa, y = Ya, verb = T, family = 'binomial', nfold = 5)
# proporción que queremos de training
training_size <- 0.8
# filas de training
training_rows <- sample(seq_len(nrow(newdata_train)),
size=floor(training_size*nrow(newdata_train)))
#training set
data_training <- newdata_train[training_rows,]
#training cuenta con la y
#validation set
# la variable objetivo por separado
data_validation <- newdata_train[-training_rows,-1] #sin la y
y <- newdata_train[-training_rows,1]
# proporción que queremos de training
training_size <- 0.8
# filas de training
training_rows <- sample(seq_len(nrow(newdata_train)),
size=floor(training_size*nrow(newdata_train)))
#training set
data_training <- newdata_train[training_rows,]
#training cuenta con la y
#validation set
# la variable objetivo por separado
data_validation <- newdata_train[-training_rows,-1] #sin la y
y <- newdata_train[-training_rows,1]
#Matriz de covariates
#data_training<-sample_train
Xa <-data_training %>% select(-1) #training menos y
Xb <-data_validation
Xc <-equallevels(newdata_test,Xa)
#para manejo de nas, si lo quito, por alguna razon la conversion a matriz rala me quita unas obs
options(na.action='na.pass')
#se quita intercepto
#se ponen todas las columnas
Xa <- sparse.model.matrix(~.+0, data = Xa)
Xb <- sparse.model.matrix(~.+0, data = Xb)
Xc <- sparse.model.matrix(~.+0, data = Xc)
#vector de Y´s
Ya<-data_training$y
#CV LASSO
# se hacen 5 folds
cvlasso_a<-cv.gamlr(x = Xa, y = Ya, verb = T, family = 'binomial', nfold = 5)
# Preparar la base de entrenamiento
library(xgboost)
dtrain <- xgb.DMatrix(Xa, label = Ya)
# Label es el target
# Preparar la base de validación
dtest <- xgb.DMatrix(Xb, label = y)
watchlist <- list(train = dtrain, eval = dtest)
# Para evaluar el performance del modelo
# Entrenamiento del modelo
param <- list(max_depth = 6, learning_rate = 0.06,
objective = "binary:logistic",
eval_metric = "logloss", subsample = 0.6, colsample_bytree = 0.7)
xgb_model <- xgb.train(params = param, dtrain,
early_stopping_rounds =  10,
nrounds = 300,
watchlist)
# Predicción
xgb_pred <- predict(xgb_model, Xb)
prepare_data<-function(data){
# QUITO CEROS Y NULLS
data[is.na(data)] <- "0"
data[is.null(data)] <- "0"
# Codifico
data$arrival_date_year<-as.factor(data$arrival_date_year)
data$arrival_date_month<-as.factor(data$arrival_date_month)
data$arrival_date_week_number<-as.factor(data$arrival_date_week_number)
data$arrival_date_day_of_month<-as.factor(data$arrival_date_day_of_month)
data$meal<-as.factor(data$meal)
data$country<-as.factor(data$country)
data$market_segment<-as.factor(data$market_segment)
data$distribution_channel<-as.factor(data$distribution_channel)
data$agent<-as.factor(data$agent)
data$company<-as.factor(data$company)
data$customer_type<-as.factor(data$customer_type)
#data$reserved_room_type<-as.factor(data$reserved_room_type)
#data$assigned_room_type<-as.factor(data$assigned_room_type)
# AD HOC
# preprocesamiento DE TIPO DE VAIRABLE adecuado
data$hotel<-as.factor(data$hotel)
data<- data %>% mutate(city_hotel=ifelse(hotel=="City Hotel",1,0))
data$hotel<-NULL
### En este caso quito espacios para que no haya problema durante la codificacion
data$deposit_type<-as.factor(data$deposit_type)
data<- data %>% mutate(deposit_type=ifelse(deposit_type=="No Deposit","A",
ifelse(deposit_type=="Non Refund","B","C")))
# quito caracteres especiales con regex para que no haya problema con codificacion
data<-data %>% mutate(market_segment=ifelse(market_segment=="Offline TA/TO",str_replace(market_segment,"/","_"),market_segment),
distribution_channel=ifelse(distribution_channel=="TA/TO",str_replace(distribution_channel,"/","_"),distribution_channel),
market_segment=str_remove_all(market_segment," "))
data$market_segment<-as.factor(data$market_segment)
data$distribution_channel<-as.factor(data$distribution_channel)
#feat eng
#### DIA DE LA SEMANA
fecha = ymd(paste(data$arrival_date_year,data$arrival_date_month,data$arrival_date_day_of_month))
data <- data %>% mutate(dia_sem = wday(fecha))
data <- data %>% mutate(dia_sem = if_else(dia_sem==1, "domingo", as.character(dia_sem)))
data <- data %>% mutate(dia_sem = if_else(dia_sem==2, "lunes", as.character(dia_sem)))
data <- data %>% mutate(dia_sem = if_else(dia_sem==3, "martes", as.character(dia_sem)))
data <- data %>% mutate(dia_sem = if_else(dia_sem==4, "miercoles", as.character(dia_sem)))
data <- data %>% mutate(dia_sem = if_else(dia_sem==5, "jueves", as.character(dia_sem)))
data <- data %>% mutate(dia_sem = if_else(dia_sem==6, "viernes", as.character(dia_sem)))
data <- data %>% mutate(dia_sem = if_else(dia_sem==7, "sabado", as.character(dia_sem)))
data$dia_sem<-as.factor(data$dia_sem)
####
####### PASCUAS
pascua <- ymd(as.character(timeDate::Easter(2015:2017)))
pascua_m1 <- ymd(as.character(timeDate::Easter(2015:2017))) - days(1)
pascua_m2 <- ymd(as.character(timeDate::Easter(2015:2017))) - days(2)
pascua_m3 <- ymd(as.character(timeDate::Easter(2015:2017))) - days(3)
pascua_m4 <- ymd(as.character(timeDate::Easter(2015:2017))) - days(4)
pascua_m5 <- ymd(as.character(timeDate::Easter(2015:2017))) - days(5)
pascua_m6 <- ymd(as.character(timeDate::Easter(2015:2017))) - days(6)
data <- data %>% mutate(fecha = fecha)
data$pascua <- as.numeric(data$fecha %in% pascua)
data$pascua_m1 <- as.numeric(data$fecha %in% pascua_m1)
data$pascua_m2 <- as.numeric(data$fecha %in% pascua_m2)
data$pascua_m3 <- as.numeric(data$fecha %in% pascua_m3)
data$pascua_m4 <- as.numeric(data$fecha %in% pascua_m4)
data$pascua_m5 <- as.numeric(data$fecha %in% pascua_m5)
data$pascua_m6 <- as.numeric(data$fecha %in% pascua_m6)
data<- data %>% mutate(semana_santa = pascua + pascua_m1 +
pascua_m2 + pascua_m3 + pascua_m4 + pascua_m5 + pascua_m6)
### AGENT Y COMPANY
data<-data %>% mutate(agent_company_identifiable =
ifelse(agent == "NULL" & company =="NULL",0,
(ifelse(agent != "NULL" & company !="NULL",2,1))),
agent_company=paste(agent,company,sep = "_"))
data$agent_company_identifiable<-as.numeric(data$agent_company_identifiable)
data$agent_company<-as.factor(data$agent_company)
### SINGLE ADULT
# se hace una varibale dummy 1 si solo son adultos
data<-data %>% mutate(singles_adults = ifelse(adults> 0 & children ==0& babies ==0 ,1,0))
##II COMBINACIONES LOCAS ###
## solamente hize una variable por cada combinacion posible
data<-data %>% mutate(dif_room= ifelse(reserved_room_type==assigned_room_type,0,1),
weekmonth=paste(arrival_date_month,arrival_date_week_number, sep = "_"),
daymont=paste(arrival_date_month,arrival_date_day_of_month, sep = "_"),
weekdaymonth=paste(weekmonth,arrival_date_day_of_month, sep ="_"),
month_diasem=paste(arrival_date_month,dia_sem, sep = "_"),
week_diasem=paste(arrival_date_week_number,dia_sem, sep = "_"),
#weekmonth_dia=paste(weekmonth,dia_sem, sep ="_"))#esta variable esta ruidosa
)
data$weekmonth<-as.factor(data$weekmonth)
data$daymont<-as.factor(data$daymont)
data$weekdaymonth<-as.factor(data$weekdaymonth)
data$month_diasem<-as.factor(data$month_diasem)
data$week_diasem<-as.factor(data$week_diasem)
#data$weekmonth_dia<-as.factor(data$weekmonth_dia)
data$children<-as.numeric(data$children)
data$reserved_room_type<-as.factor(data$reserved_room_type)
data$assigned_room_type<-as.factor(data$assigned_room_type)
data$deposit_type<-as.factor(data$deposit_type)
###Tasa de rechazos:
data<-data %>% mutate(total=previous_cancellations+previous_bookings_not_canceled,
tasa_canc= previous_cancellations/total)
data$tasa_canc<-as.numeric(data$tasa_canc)
data$tasa_canc[is.na(data$tasa_canc)] <- 0
#Se agrega tasa de cancelados multiplicado por cantidad de reservacione4s totales
data<-data %>% mutate(mag_tasa_can=total*tasa_canc)
### MAS COMBINACIONES LOCAS
### market_segment y distribution channel
data<-data %>% mutate(market_dist=paste(market_segment,distribution_channel, sep = "_"), cust_deposti=paste(customer_type,deposit_type, sep = "_"),
cust_segment=paste(customer_type,market_segment, sep = "_"))
data$market_dist<-as.factor(data$market_dist)
data$cust_deposti<-as.factor(data$cust_deposti)
data$cust_segment<-as.factor(data$cust_segment)
#### LEAD TIME
library(Hmisc) # cut2
data<-data %>% mutate(lead_categoric= as.factor(cut2(data$lead_time, g=4)),
lead_deposit=paste(deposit_type,lead_categoric, sep = "_"),
lead_week=paste(arrival_date_week_number,lead_categoric, sep = "_"),
meal_reserv=paste(meal,reserved_room_type, sep = "_"))
data$lead_deposit<-as.factor(data$lead_deposit)
data$lead_week<-as.factor(data$lead_week)
data$meal_reserv<-as.factor(data$meal_reserv)
data$lead_categoric<-NULL
## coungtry dates
data<-data %>% mutate(
country_month=paste(country,arrival_date_month, sep = "_"))
data$country_month<-as.factor(data$country_month)
data$fecha<-NULL
data
}
#aplico la preparacion de los datos a cada set
train<-prepare_data(train)
test<-prepare_data(test)
#summary(train)
# aplico el one hot encoding
newdata_train<-train
#newdata_train <-dummy_cols(train,split = T)
newdata_test<-test
#newdata_test <- dummy_cols(test,split = T)
# proporción que queremos de training
training_size <- 0.8
# filas de training
training_rows <- sample(seq_len(nrow(newdata_train)),
size=floor(training_size*nrow(newdata_train)))
#training set
data_training <- newdata_train[training_rows,]
#training cuenta con la y
#validation set
# la variable objetivo por separado
data_validation <- newdata_train[-training_rows,-1] #sin la y
y <- newdata_train[-training_rows,1]
#Matriz de covariates
#data_training<-sample_train
Xa <-data_training %>% select(-1) #training menos y
Xb <-data_validation
Xc <-equallevels(newdata_test,Xa)
#para manejo de nas, si lo quito, por alguna razon la conversion a matriz rala me quita unas obs
options(na.action='na.pass')
#se quita intercepto
#se ponen todas las columnas
Xa <- sparse.model.matrix(~.+0, data = Xa)
Xb <- sparse.model.matrix(~.+0, data = Xb)
Xc <- sparse.model.matrix(~.+0, data = Xc)
#vector de Y´s
Ya<-data_training$y
#CV LASSO
# se hacen 5 folds
cvlasso_a<-cv.gamlr(x = Xa, y = Ya, verb = T, family = 'binomial', nfold = 5)
#Grafica
plot(cvlasso_a)
plot(cvlasso_a$gamlr)
# Identificador para el lambda deseado
# Valor del lambda deseado
#lambda resultante
a_lambda<- colnames(coef(cvlasso_a, select="min"))
cvlasso_a$gamlr$lambda[a_lambda]
#Predicciones
lasso_score <- predict(cvlasso_a,
newdata = Xb,
type="response",
select = "min" )
#dataframe
lasso_validation <- data.frame(y, lasso_score)
colnames(lasso_validation)[2] <- c('lasso_score')
library(MLmetrics)
LogLoss(lasso_validation$lasso_score,lasso_validation$y)
#Predicciones
lasso_score <- predict(cvlasso_a,
newdata = Xc,
type="response",
select = "min")
length(lasso_score)
#dataframe
lasso_test <- data.frame(test_id, lasso_score)
colnames(lasso_test) <- c('id','prob')
write.csv(lasso_test,"submission.csv",row.names = F)
# Preparar la base de entrenamiento
library(xgboost)
dtrain <- xgb.DMatrix(Xa, label = Ya)
# Label es el target
# Preparar la base de validación
dtest <- xgb.DMatrix(Xb, label = y)
watchlist <- list(train = dtrain, eval = dtest)
# Para evaluar el performance del modelo
# Entrenamiento del modelo
param <- list(max_depth = 6, learning_rate = 0.06,
objective = "binary:logistic",
eval_metric = "logloss", subsample = 0.6, colsample_bytree = 0.7)
xgb_model <- xgb.train(params = param, dtrain,
early_stopping_rounds =  10,
nrounds = 300,
watchlist)
# Predicción
xgb_pred <- predict(xgb_model, Xb)
XGpred<-data.frame(y, xgb_pred)
colnames(XGpred)<-c("y","xgb_pred")
LogLoss(XGpred$xgb_pred,XGpred$y)
#Predicciones
pred_xg <- predict(xgb_model,
newdata = Xc,
type="response")
#dataframe
XGpred_test <- data.frame(test_id, pred_xg)
colnames(XGpred_test) <- c('id','prob')
write.csv(XGpred_test,"submission.csv",row.names = F)
